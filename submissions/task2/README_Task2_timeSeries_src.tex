\documentclass{article}

\usepackage[T2A]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[english,russian]{babel}
\usepackage{indentfirst}
\usepackage{misccorr}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}


\title{README для задания 2}
\author{Пожилая саламандра}
\date{December 2019}

\setlength{\parindent}{2em}
\setlength{\parskip}{1em}

\begin{document}

\maketitle

\tableofcontents
\newpage
 
 
\section{Теория временных рядов}
  
  \subsection{Определения из курса ТВиМС}
  
    \subsubsection{Теория вероятности}
     
      \textbf{Случайная величина (с.в.)} - числовая функция, заданная на некотором вероятностном пространстве $(\Omega, P): X = X(\omega), \omega \in \Omega.$\par
      
      \textbf{Функция распределения} с.в. - числовая функция числового аргумента, определяемая равенством:
      \begin{equation}
        F(x) = P(X \leq x), \quad x \in R
      \end{equation}
      (R - множество действительных чисел).\par
      
      Существует два класса с.в. - \textsl{дискретные} и \textsl{непрерывные}.\par
      
      C.в. называется \textbf{дискретной}, если множество её значений конечно или счётно. Одно из представлений дискретной случайной величины:
      
      \begin{equation}
        X = (\overline{x}, \overline{p} : p_k = P(X = x_k)),
      \end{equation}
      где $k$ - не более, чем счётное.\par
      
      C.в. называется \textbf{непрерывной}, если её функция распределения дифференцируема, т.е. существует производная $p(x) = F'(x)$, называемая \textbf{плотность распределения} с.в. $X$.\par
      
      В частности, $F(x) = \int\limits_{-\infty}^x p(y)dy$.  
     
      \textbf{Математическое ожидание (м.о.)} \textsl{(среднее значение)} дискретной с.в. $X$, имеющей распределение (2) - есть по определению\footnote{При условии его абсолютной сходимости} ряд
      \begin{equation}
        E(X) = \sum\limits_k x_kp_k
      \end{equation}
      \par
      
      Для непрерывной случайной величины $X$ с плотностью распределения $p(x)$ м.о. - это интеграл\footnote{Также при условии,что он абсолютно сходится}
      \begin{equation}
        E(X) = \int\limits_{-\infty}^{+\infty} xp(x)dx
      \end{equation}
      
      \textbf{Дисперсия} с.в. $X$ - числовая характеристика, отражающая степень <<разброса>> случайной величины относительно среднего значения. Она определяется равенством
      \begin{equation}
        Var(X) = E(X - EX)^2.
      \end{equation}\par
  
    \subsubsection{Математическая статистика}
      
      \textbf{Случайной выборкой} \textsl{объема n} называется последовательность наблюдений $X_1, \ldots , X_n$, если они получены как независимые реализации некоторой с.в. $X$ с распределением $F(x)$.
      
      \textbf{Выборочными статистиками} $выборки X_1, \ldots, X_n$ называются следующие величины:
      \begin{itemize}
          \item выборочное среднее:
          \begin{equation}
              \overline{X} = \frac{1}{n}\sum\limits_{i=1}^n X_i;
          \end{equation}{}
          \item выборочная дисперсия: 
          \begin{equation}
              Var(X) = \frac{1}{n-1}\sum\limits_{i=1}^n (X_i - \overline{X})^2;
          \end{equation}{}
          \item размах:
          \begin{equation}
              d = \max_{1\leq i \leq n} {X_i} - \min_{1\leq i \leq n} {X_i}
          \end{equation}{}\par
          Если есть ещё одна случайная выборка $Y_1,\ldots,Y_n$, то определяются также:
          \item выборочная ковариация:
          \begin{equation}
              Cov(X,Y) = \frac{1}{n-1} \sum\limits_{i=1}^n (X_i - \overline{X})(Y_i - \overline{Y});
          \end{equation}{}
          \item выборочная корреляция:
          \begin{equation}
              Corr(X,Y) = \frac{Cov(X,Y)}{\sqrt{Var(X)Var(Y)}}
          \end{equation}{}
      \end{itemize}
      
  
  \subsection{Временные ряды}
  
  \textbf{Временной ряд} - собранный в разные моменты времени статистический материал о значении каких-либо параметров (в простейшем случае одного) исследуемого процесса.\par
  
  \textbf{Стационарность временного ряда в узком смысле} - ряд $y_t^0$ называется строго стационарным (\textsl{strictly stationarity}) или стационарным в узком смысле, если совместное распределение $m$ наблюдений $y_{t_1}^0, \ldots, y_{t_m}^0$ не зависит от сдвига во времени, то есть совпадает с распределением $y_{t_1+t}^0 \ldots, y_{t_m+t}^0$ для любых $m, t, t_1, \ldots, t_m$.\par
  
  \textbf{Стационарность временного ряда в широком смысле} - ряд $y_t$ называется слабо стационарным (\textsl{weak stationarity}) или стационарным в широком смысле, если такие статистические характеристики временного ряда как его математическое ожидание (среднее), дисперсия (ср. кв. отклонение) и ковариация не зависят от момента времени:
  \begin{equation}
    {E(y_t) = \mu < \infty, \quad Var(y_t) = \gamma_0, \quad Cov(y_t, y_{t-k}) = \gamma_k}
  \end{equation}\par
  
  Конечно, из строгой стационарности следует слабая стационарность (при условии конечности первого и второго моментов распределения). В дальнейшем мы будем везде под <<стационарностью>> понимать \textsl{слабую} стационарность.\par 
  
  \textbf{Авторегрессионная (AR-) модель} (англ. \textsl{autoregressive model}) — модель временных рядов, в которой значения временного ряда в данный момент линейно зависят от предыдущих значений этого же ряда. Авторегрессионный процесс порядка $p$ (AR($p$)-процесс) определяется следующим образом:
  \begin{equation}
      X_t = c + \sum\limits_{i=1}^{p} a_i X_{t-i} + \varepsilon_t ,
  \end{equation}
  где где $a_1,\ldots ,a_p$ — параметры модели (коэффициенты авторегрессии), $c$ — постоянная (часто для упрощения предполагается равной нулю), $\varepsilon_t$ — белый шум.\par
  
  \textbf{Модель авторегрессии - скользящего среднего (APCC)} - \textsl{autoregressive moving average (ARMA)} - одна из математических моделей, использующихся для анализа и прогнозирования стационарных временных рядов в статистике. Модель ARMA обобщает две более простые модели временных рядов - модель авторегрессии (AR) и модель скользящщего среднего (MA). \par
  
  Моделью ARMA(p,q), где p и q - целые числа, задающие порядок модели, называется следующий процесс генерации временного ряда:
  \begin{equation}
  	x_k = c + \varepsilon_k + \sum\limits_{i=1}^p a_i x_{k-i} + \sum\limits_{i=1}^q b_i \varepsilon_{k-i}
  \end{equation}
  где $a_i$ и $b_i$ - параметры модели (действительные числа, соответственно, авторегресссионные коэффициенты и коэффициенты скользящео среднего); $c$ - константа, $\varepsilon_k$ - белый шум. \par
  
  \textbf{ARIMA (autoregressive integrated moving average)}; модель Бокса - Дженкинса - расширение моделей ARMA для нестационарных рядов, которые можно сделать стационарными взятием разностей некоторого порядка от исходного временного ряда (так называемые интегрированные или разностно-стационарные ряды). Модель ARIMA($p, d, q$) означает, что разности временного ряда порядка $d$ подчиняются модели ARIMA($p, q$).\par

\newpage

\section{Программная реализация на языке Руthon}
  
  \subsection{Используемые библиотеки}
  
  \begin{itemize}
  	\item numpy
  	\item pandas
  	\item xlrd
  	\item statistics
  	\item statsmodels.
  	\begin{itemize}
  		\item tsa.adfvalues
  		\item compat.python
  		\item graphics.tsaplots.plot\underline{ }acf, plot\underline{ }pacf
  		\item regression.linear\underline{ }model.OLS
  		\item tsa.arima\underline{ }model
  		\item tools.add\underline{ }constant
  	\end{itemize}
    \item sklearn.metrics.mean\underline{ }squared\underline{ }error
    \item sklearn.metrics.r2\underline{ }score
    \item warnings
  \end{itemize}
  
  \subsection{Список реализованных функций}
  
  \begin{itemize}
  	\item diff\underline{ }operator
  	
  \end{itemize}
  
  \subsection{Описание алгоритмов некоторых функций}
  
  \subsection{Инструкция по запуску и установке}
  
\newpage  
  
\section{Ход решения задачи}

  \subsection{Проверка стационарности ряда}
    
    \subsubsection{Тест Дики-Фуллера}
    
    Тест Дики-Фуллера используется для проверки ряда на стационарность, а также для проверки гипотезы о единичном корне (что, по сути, одно и то же), то есть гипотезы о равенстве коэффициента $a$ в AR(1):
    
    $y_t = a*y_{t-1} + \varepsilon_t,$
    
    где $y_t$ - временной ряд, а $\varepsilon$ - ошибка.
    \\
    Авторегрессионное уравнение AR(1) можно также представить в виде:
    
    $\Delta{y_t} = b*y_{t-1} + \varepsilon_t,$
    
    где $b = a - 1,$ а $\Delta{y_t} = y_t - y_{t-1}$
    \\
    Если ряд, полученный из первых разностей элементов исходного ряда, - стационарный, то гипотеза о единичном корне принимается.
    \\
    Результатом теста является DF-статистика - t-статистика (не путать с распределением Стьюдента) для проверки значимости коэффициентов линейной регрессии. Если полученная статистика больше критического значения данной статистики, то ряд является нестационарным, иначе - стационарным.
    \\
    На вход функции df\underline{ }test() подается Numpy Array со значениями ряда. Вычисляется максимальное значение лага, то есть временной сдвиг (количество предшествующих элементов, участвующих в разложении текущего). После получения массива с первыми разностями значений временного ряда строится полная карта лагов. Вычисляется стартовое значение лага, а затем оптимальное значение лага (при помощи функции get\underline{ }lag(), которая путем минимизации критерия Акаике подбирает оптимальные информационный критерий и лаг), после чего снова строится карта лагов. После вычисления необходимых данных строится методом наименьших квадратов аппроксимационная функция значений временного ряда, из которой далее получаем необходимую DF-статистику. После сравнения полученной статистики с соответствующим критическим значением делаем вывод о стационарности или её отсутствии.
    
    \subsubsection{Выводы}
    
    \subsubsection{Оценка достоверности статистики}
  
  \newpage
    
  \subsection{Разложение временного ряда}
    
    \subsubsection{Тренд, сезональность, остаток (по $+, \times$ -ым моделям)} 
    
    \subsubsection{Оценка стационарности полученных временных рядов}
    
    \subsubsection{Анализ и визуализация}
  
  \newpage
    
  \subsection{Проверка на интегрированность порядка $k$}
  Разностный оператор: \begin{align*}
                    \diff \nabla= 1-B  \\
                    \diff X_t \nabla= X_t - X_{t-1} 
                    \end{align*}  \par
    Полином AR: $\phi(z) = 1-  − \phi_1 z − \ldots − \phi_p z^p \par$
    AR-оператор: $\phi(B) = 1 − \phi_1 B − \ldots − \phi_p B^p \par$
    Полином MA: $\theta$(z) = 1 +  $\theta$_1 z + \ldots +  $\theta$_q z^q  \par
    MA-оператор:  $\theta$(B) = 1 +  $\theta$_1 B + \ldots +  $\theta$_q B^q  \par
    ARMA(p,q):  $X_t$  - это ARMA(p,q)  процесс, если он стационарен и имеется белый шум  Z_t, такой как: $\phi(B)X_t =  $\theta$(B)Z_t$ \par
    ARIMA(p,d,q):  $X_t$  - это ARIMA(p,d,q)  процесс, если $\theta$^d $X_t$  - это ARMA (p,q): $\phi$(B)$\nabla$^dX_t = $\theta$(B)Z_t \par
    Ряд называется интегрируемым порядка k, если его разности порядка k-1 включительно нестационарны, а k-я разность — стационарна.
    
  \subsection{Применение модели ARIMA}
  
    \subsubsection{Подборка необходимых параметров с помощью функций автокорреляции, частичной автокорреляции}
    Параметры модели AR(p) подбираются через график PACF (функции частичной автокорреляции)  . Выбор параметров происходит выбор наиболее выбивающихся точек из синей области графика.\par
    Аналогично происходит выбор параметров модели MA(q).
    
    \subsubsection{Отбор моделей}
    Отбор моделей происходит иттерационным методом "пробега" по возможным комбинациями ARIMA(p,d,q) модели, где p - возможные параметры AR(p), d - порядок интегрированности, а q - возможные параметры MA(q).\par
    Выбор наилучшей модели происходит по наименьшему показателю AIC для итогового теста. 
    
  \subsection{Работа с тестовой выборкой}
  
    \subsubsection{Предсказание значений}
    В нашей программе реализованно две различных функции предсказания значений с помощью ARIMA(p,d,q).\par
    1) forecast() - для реализации One-Step Out-of-Sample Forecast, когда ARIMA(p,d,q) дообучается на каждом шаге прохождения тестовой таблицы. \par
    2) predict() - для реализации полного предсказания n шагов вперёд.\par
    Очевидно, что показатели AIC (информационный критерий Акаике) и $r^2 score$ лучше у 1 реализации.\par
    \subsubsection{Визуализация, подсчёт $r^2 score$}
    Визуализация проводится через mathplotlib с использованием seaborn, а также $r^2 score$ берётся из библиотеки sklearn \par
    $r^2 score$ - коэфициент детерминации - это доля дисперсии зависимой переменной, объясняемая рассматриваемой моделью зависимости, то есть объясняющими переменными. От меньше 1 и может быть отрицательным. 
   \subsubsection{Отбор наилучших моделей с помощью информационного критерия Акаике}
   Информационный критерий Акаике - AIC - критерий, применяющийся исключительно для выбора из нескольких статистически моделей.\par
   В общем случае: \par
  AIC = 2k - 2ln(L), где k — число параметров в статистической модели, L — максимизированное значение функции правдоподобия модели.
  Чем AIC меньше, тем лучше подобрана модель.
\newpage
  

\section{Список участников и их вклад в проект}

\begin{itemize}
    \item Денисов Никита - тест Дики-Фуллера
    \item Ловягин Андрей - ARIMA
    \item Иванков Михаил - компиляция README, декомпозиция
\end{itemize}{}

\section{Использованная литература}

\begin{itemize}
    \item Эконометрика. Начальный курс.  Магнус Я.Р., Катышев П.К., Пересецкий А.А.: 6-е изд., перераб. и доп. - М.: Дело, 2004.
    \item Лекции по временным рядам. Канторович Г.Г.
    \item wikipedia.org, англ. и рус. версия, различные статьи
    \item 
\end{itemize}
  

\end{document}
